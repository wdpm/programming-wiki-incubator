# vol31

## 本期主題

### 编码辅助反模式

我们在过度亢奋的 AI 领域中已经看到了一些反模式的出现，包括错误地认为 **人类可以完全用 AI 取代结对编程伙伴 、过度依赖编码辅助建议、生成代码的质量问题以及代码库的快速膨胀**。

AI 往往通过蛮力而非抽象概念解决问题，比如使用大量嵌套条件语句而不是应用一个策略设计模式。代码质量问题尤其突显了开发者和架构师需要持续关注的领域，以确保他们不会在一堆“能用但很糟糕”的代码中迷失。

团队成员应该加强良好的工程实践 ，如**单元测试、架构适应度函数以及其他经过验证的治理和检验技术**，确保 AI 能够帮助你的工作，而不是通过复杂性加密你的代码库。

### Rust 绝非 “锈”铁

当替换旧的系统级实用工具时，它是首选语言，同时也是为了提高性能而重写生态系统某些部分的选择――基于 Rust 的工具最常见的描述是“极其快速”。

### WASM 逐步崛起

WASM（WebAssembly）是一种用于基于栈的虚拟机的二进制指令格式，能够在浏览器沙箱中运行复杂的应用程序。WASM 可以在现有的JavaScript 虚拟机中运行，使得开发者过去只能在原生框架和扩展中实现的应用程序可以嵌入到浏览器中。

### 生成式 AI 工具的寒武纪大爆发

我们对支持语言模型的技术生态的迅猛发展感到惊讶：包括安全边界、评估工具、构建智能体的工具、处理结构化输出的框架、向量数据库、云服务和可观察性工具。最初通过简单文本提示与语言模型互动的体验，如今已转变为软件产品的工程化。虽然这些产品可能无法实现人们在向 ChatGPT发送首个提示词后所做的梦想和夸大宣传，但我们看到了生成式人工智能的合理高效的应用，这些工具、平台和框架在将基于 LLM 的解决方案投入生产中发挥了重要作用。



## 技术

### 采纳

- 1%金丝雀。虽然金丝雀发布有助于更快地获取用户反馈，但从小部分用户开始测试是必要的，以降低大规模功能发布的风险并控制其影响。
- 组件测试。单元测试往往迫使组件暴露本应是纯内部的功能，而基于浏览器的测试则运行缓慢，更容易出错且更难调试。建议是进行大量的组件测试，并使用类似 jsdom 这样的库在内存中运行组件测试。当然，像 Playwright 这样的浏览器工具仍然适用于端到端的测试，但不应用于组件测试。
- 持续部署。持续部署是指自动将每个通过自动化测试的更改部署到生产环境中的实践。这种做法是快速反馈循环的关键推动力，使组织能够更快速和高效地为客户提供价值。持续部署与持续交付的区别在于，它只要求代码“可以” 在任何时候进行部署；并不要求每个更改“实际被”部署到生产环境中。
- 检索增强生成（RAG）。在 RAG 技术中，相关且可信的文档信息存储在数据库中。在给定的提示词
  （prompt）下，系统会查询数据库，检索相关文档，并将这些文档的内容与提示词结合，从而为 LLM 提供更丰富的上下文。这不仅提高了输出质量，还大大减少了幻觉现象。我们的经验表明，精心构建的较小上下文有时能比广泛的大上下文产生更好的效果。并且使用大上下文也会导致速度变慢且成本更高。我们过去依赖存储在向量数据库中的向量嵌入（embedding）来识别额外的上下文，但现在看到了重排序和混合搜索的趋势：搜索工具如 Elasticsearch Relevance Engine 以及诸如 GraphRAG 等利用 LLM 创建的知识图谱的方法开始被使用。

### 试验

- 领域叙事（Domain storytelling）。领域叙事是一种引导技术，业务专家被提示描述业务中的活动。在专家的叙述过程中，**主持人使用图示语言捕捉实体和参与者之间的关系和动作**。使这些故事可视化的过程有助于澄清和发展参与者之间的共同理解。
- 微调嵌入模型。在构建基于 检索增强生成（RAG）的大语言模型应用时，嵌入的质量直接影响到相关文档的检索和响应质量。
- 用LLMs进行函数调用。用 LLMs 进行函数调用是指通过根据给定查询和相关文档确定并调用适当的函数，将 LLM 与外部函数、API 或工具集成的能力。这将 LLM 的实用性扩展到文本生成之外，使它们能够执行特定任务，如信息检索、代码执行和 API 交互。通过触发外部函数或 API，LLM 可以执行之前超出其独立能力的操作。
- LLM as a judge。许多我们构建的系统具有两个关键特征：一是能够根据大量数据集中的问题提供答案，二是几乎不可能追踪到该答案的得出过程。尽管这些系统具有不透明性，我们仍然希望评估并提高其响应质量。通过大语言模型（LLM）作为评判者的模式，我们可以使用一个 LLM 来评估另一个系统的响应。

- Passkeys。在 FIDO 联盟的引导下，并由 Apple、Google 和 Microsoft 支持，passkeys 正逐步接近主流可用性。使用 passkeys 设置新登录会生成一对密钥：网站接收公钥，而用户保留私钥。登录过程使用非对称加密，用户通过证明自己拥有私钥来进行身份验证，该私钥存储在用户设备上，永远不会发送到网站。
- 小语言模型（SLMs）。大语言模型（LLMs）在许多应用领域中被证明是有用的，但它们的体积庞大可能会带来一些问题：响应一个提示需要大量计算资源，导致查询速度慢且成本高；这些模型是专有的，体积庞大，必须由第三方托管在云中，这可能对敏感数据造成问题；而且在大多数情况下，训练一个模型的费用非常高。最后一个问题可以通过 RAG 模式来解决，该模式绕过了训练和微调基础模型的需求，但成本和隐私问题往往依然存在。与更流行的 LLMs 相比，SLMs 的参数更少、精度较低，通常在 35 亿到 100 亿个参数之间。
- 用于测试和训练模型的合成数据。合成数据集创建涉及生成可以模拟现实世界场景的人工数据，而无需依赖敏感或有限访问的数据源。虽然合成数据在结构化数据集中的应用已得到广泛探索（例如，用于性能测试或隐私安全环境），但我们看到在非结构化数据中重新使用合成数据的趋势。
- 利用生成式AI理解遗留代码库。生成式 AI（GenAI）和大型语言模型（LLMs）能帮助开发人员编写和理解代码。尤其是在处理遗留代码库时，这种帮助显得尤为有用，特别是当文档质量差、过时或具有误导性时。知识图谱可以保留代码库的结构化信息，而这往往超出了 LLM 从文本代码中推导的内容。这对于那些不具备自我描述性和一致性的遗留代码库尤其有帮助。另一个提升代码理解的机会是，图谱可以通过现有的或 AI 生成的文档、外部依赖关系、业务领域知识等内容进一步丰富，从而让AI 的工作更加轻松。

### 评估

- AI 团队助手。AI 编码辅助工具通常是在帮助和增强个人贡献者的工作方面被讨论的。然而，软件交付始终是团队合作的过程，因此您应该寻找创建 AI 团队助手 的方法，以帮助形成 10 倍效能的团队，而不是一群 AI 辅助孤立的 10x工程师。幸运的是，最近工具市场的发展让我们更接近于实现这一目标。[Unblocked](https://www.thoughtworks.com/cn/radar/platforms/unblocked) 是一个将团队的所有知识来源汇聚在一起，并智能地整合到团队成员工具中的平台。而 Atlassian 的 [Rovo](https://www.atlassian.com/software/rovo) 则将 AI 引入最广泛使用的团队协作平台，为团队提供新的搜索类型和访问其文档的方式，并通过 Rovo 代理解锁新的自动化和软件实践支持方式。
- 动态少样本提示。动态少样本提示 构建在 少样本提示（few-shot prompting）的基础上，通过动态地在提示中包含特定的示例来引导模型的响应。调整这些示例的数量和相关性可以优化上下文长度和相关性，从而提升模型的效率和性能。
- 用于数据产品的 GraphQL。用于数据产品的 GraphQL 是指使用 GraphQL 作为数据产品的输出端口，供客户端消费产品的技术。我们之前讨论过 GraphQL 作为一种 API 协议，它使开发者能够创建一个统一的 API 层，抽象底层数据的复杂性，为客户端提供一个更加一致且易于管理的接口。
- LLM 驱动的自主代理。随着诸如 Autogen 和 CrewAI 等框架的出现，LLM 驱动的自主代理正在超越单一代理和静态的多代理系统。这项技术允许开发人员将复杂的任务分解为多个小任务，再交由不同角色的代理完成。开发人员可以使用预配置的工具来执行任务，代理之间通过对话来协调任务流程。
- 可观察性 2.0。可观察性 2.0 代表了一种从传统的、分散的监控工具向统一方法的转变，它利用结构化的、高基数的事件数据存储在单一数据存储中。该模型捕捉丰富的、带有详细元数据的原始事件，为综合分析提供单一的真实来源。通过以原始形式存储事件，这种方法简化了关联性分析，支持实时和取证分析，并能够深入了解复杂的分布式系统。
- 本地设备上的大语言模型推理。大语言模型（LLMs）现在可以在网络浏览器和智能手机、笔记本电脑等边缘设备上运行，这使得本地 AI 应用成为可能。这允许在不传输到云端的情况下安全处理敏感数据，为边缘计算、实时图像或视频处理等任务提供极低的延迟，通过本地计算降低成本，并在网络连接不稳定或不可用时依然能够正常工作。
- 从LLMs 获取结构化输出。从 LLMs 获取结构化输出 是指通过定义的结构模式来约束语言模型的响应。这可以通过指示通用模型以特定格式响应，或者通过微调模型使其“原生”输出例如 JSON 的结构化数据来实现。OpenAI 现在支持结构化输出，允许开发人员提供 JSON Schema、pydantic 或 Zod 对象来约束模型响应。这种能力在函数调用、API 交互和外部集成中尤其有价值，因为这些场景中格式的准确性和一致性至关重要。此外，结构化输出已被证明可以减少模型输出中的幻觉现象。

### 暂缓

- 自满于 AI 生成的代码。AI 编程助手，如 GitHub Copilot 和 Tabnine，已经变得非常受欢迎。根据 StackOverflow 2024 年开发者调查 的数据，“72% 的受访者对开发中的 AI 工具持赞成或非常赞成的态度”。尽管我们也看到了这些工具的好处，但我们对它们在中长期对代码质量的影响持谨慎态度，并提醒开发者警惕 自满于 AI 生成的代码 。在经历了几次积极的 AI 辅助体验后，很容易在审查 AI 建议时变得不够谨慎。像 [GitClear 的这项研究](https://gitclear-public.s3.us-west-2.amazonaws.com/Coding-on-Copilot-2024-Developer-Research.pdf) 显示了代码库快速增长的趋势，我们怀疑这与更大的 Pull Request 有关。还有 [GitHub 的这项研究](https://github.blog/2024-05-13-research-quantifying-github-copilots-impact-in-the-enterprise-with-accenture/) 让我们开始思考，提到的15% 的 Pull Request 合并率的增加是否真的是好事，**还是人们因为过于信任 AI 的结果而更快地合并了更大的请求**。我们仍在使用 一年多前提供的基本 “入门建议”，也就是要**警惕自动化偏见、沉没成本谬误、锚定偏见和审查疲劳**。我们还建议程序员建立一个良好的在何时何地不使用和信任 AI 心理框架 。

- 企业范围的集成测试环境。创建企业范围的集成测试环境是一种常见且浪费的做法，会拖慢整个开发流程。这些环境往往成为难以复制的珍贵资源，成为开发的瓶颈。**由于不同环境之间不可避免的数据和配置开销差异，它们还会提供一种虚假的安全感**。讽刺的是，常见的对替代方案（如临时环境或多个本地测试环境）的反对意见是成本问题。然而，这种观点未能考虑到企业级集成测试环境所造成的延迟成本，因为开发团队往往需要等待其他团队完成任务或等待依赖系统的新版本部署。
- 禁用大语言模型。与其在工作场所全面禁用大语言模型，组织应专注于提供一套经过批准的 AI 工具。禁令只会促使员工寻找未经批准且可能不安全的替代方案，带来不必要的风险。如果公司不提供安全且获得认可的替代方案，员工可能会使用未经批准的大语言模型，这会带来知识产权、数据泄露和法律责任的风险。**相反，提供安全、经企业批准的大语言模型或AI 工具可以确保安全性和生产力的双赢**。一个良好管理的方案能够帮助组织管理数据隐私、安全性、合规性和成本问题，同时赋能员工利用大语言模型的功能。最理想的情况下，对 AI 工具的妥善管理访问可以加速组织学习如何在工作场所中最好地利用 AI。
- 使用AI代替结对编程。现在大家都会对编码助手们提出同样的问题：一个程序员可以选择与人工智能，而不是另外一个程序员，进行结对编程，从而达到同样的团队产出吗？ Github Copilot 甚至自称为“你的 AI 结对程序员”。然而当大家都认为编程助手可以在结对编程方面带来好处时，我们还是不建议完全 使用 AI代替结对编程。把编码助手当做结对编程者忽略了结对编程的一个关键收益：它可以让团队而不只是个人变得更好。**在帮助解决难题，学习新技术，引导新人，或者提高技术任务的效率从而让团队更关注战略性设计等这些方面，使用编程助手确实大有裨益。**但在诸如将正在进行的工作的数量控制在低水平，减少团队交接与重复学习，让持续集成成为可能，或者改善集体代码所有权等等这些团队合作相关的层面，它没有带来什么好处。



## 平台

### 采纳



### 试验

- [Databricks Unity Catalog](https://www.databricks.com/product/unity-catalog)。它是一种用于数据治理的解决方案，适用于在 lakehouse 中的资产，例如文件、表或机器学习模型。它是开源 Unity Catalog 的托管版本，可用于管理和查询存储在外部存储或由 Databricks 管理的数据。
- [FastChat](https://github.com/lm-sys/FastChat) 是一个开放平台，用于训练、服务和评估大型语言模型。我们的团队利用其模型服务能力来托管多个模型 ― Llama 3.1（8B and 70B）、Mistral 7B 和 Llama-SQL ― 出于不同的目的，所有模型均以一致的OpenAI API 格式运行。FastChat 采用控制器 - 工作者架构，允许多个工作者托管不同的模型。它支持不同类型的工作者，如 vLLM、LiteLLM 和 MLX 。我们选择使用 vLLM 模型工作者，以利用其在高吞吐量的优势。根据使用案例的不同（比如延迟或吞吐量），可以创建和扩展不同类型的 FastChat 模型工作者。例如，用于开发者 IDE 中代码建议的模型需要低延迟，这就可以通过多个 FastChat 工作者进行扩展，以有效处理并发请求。相反，用于 Text-to-SQL 的模型由于需求较低或性能要求不同，则不需要多个工作者。
- [GCP Vertex AI Agent Builder](https://cloud.google.com/products/agent-builder)。GCP Vertex AI Agent Builder 提供了一个灵活的平台，可以通过自然语言或代码优先的方式创建 AI 代理。该工具通过第三方连接器无缝集成企业数据，并且拥有构建、原型设计和部署 AI 代理所需的全部工具。
- [Langfuse](https://github.com/langfuse/langfuse)。LLM（大型语言模型）像黑箱一样运作，非常难以确定它的行为。可观察性对于打开这个黑箱并理解 LLM 应用程序在生产环境中的运作至关重要。我们团队曾用它来观察、监控和评估基于 LLM 的应用程序。它的追踪、分析和评估能力使我们能够分析完成性能和准确性，管理成本和延迟，并理解生产使用模式，从而促进持续的数据驱动改进。仪器数据提供了请求 - 响应流和中间步骤的完整可追溯性，这可以作为测试数据，在部署新变更之前验证应用程序。我们已将 Langfuse 与 RAG（检索增强生成）等 LLM 架构，以及 大语言模型驱动的自主代理 一起使用。例如，在基于 RAG 的应用程序中，分析低评分的对话追踪有助于识别架构的哪个部分（如预检索、检索或生成）需要改进。当然，在这一领域，另一个值得考虑的选项是 [Langsmith](https://www.langchain.com/langsmith) 。
- Qdrant。[Qdrant](https://github.com/qdrant/qdrant) 是一个开源的向量相似度搜索引擎和数据库，使用 Rust 编写。它支持多重文本和多模态密集 向量嵌入模型 。可以把Qdrant 作为一个企业级 Vector Store 使用，利用 多租户 技术将向量嵌入存储为独立的集合，从而隔离不同产品的知识库。用户访问策略则在应用层中进行管理。
- Vespa 。 [Vespa](https://vespa.ai/) 是一个开源搜索引擎和大数据处理平台。它特别适合于需要低延迟和高吞吐量的应用。可以使用 Vespa 实现混合搜索的能力，能够使用多种检索技术高效过滤和排序多种类型的元数据，实施多阶段排名，针对每个文档索引多个向量（例如，对于每个数据块），而无需将所有元数据复制到单独索引的文档中，并能够同时从多个索引字段中检索数据。

### 评估

- Azure AI Search。[Azure AI Search](https://azure.microsoft.com/en-us/products/ai-services/ai-search)，前称 Cognitive Search，是一个云端搜索服务，专为处理结构化和非结构化数据而设计， 适用于知识库等应用场景，尤其适用于检索 增强生成（RAG）设置。它支持多种搜索方式，包括关键字搜索、 向量搜索和混合搜索。该服务可以自动导入常见的非结构化数据格式， 例如 PDF、DOC 和 PPT，从而简化创建可搜索内容的流程。此外，它还与其他 Azure 服务集成，如 Azure  OpenAI，使用户能够以最少的手动集成工作构建应用程序。
- [Databricks Delta Live Tables](https://www.databricks.com/product/delta-live-tables)。Databricks Delta Live Tables 是一个声明式框架，旨在构建可靠、可维护和可测试的数据处理管道。它允许数据工程师使用声明式方法定义数据转换，并自动管理底层基础设施和数据流。Delta Live Tables 的一个突出特点是其强大的监控能力。它提供了整个数据管道的有向无环图（DAG），直观地表示从源到最终表的数据移动，可以帮助数据工程师和数据科学家跟踪数据血缘和依赖关系。Delta Live  Tables 深度集成到 Databricks 生态系统中，这也带来了一些定制接口的挑战。建议团队在使用 Delta Live  Tables 之前仔细评估输入和输出接口的兼容性。
- [Elastisys Compliant Kubernetes](https://elastisys.io/compliantkubernetes/ciso-guide/) 。Elastisys Compliant Kubernetes 是一个专门设计的 Kubernetes 发行版，旨在满足严格的监管和合规要求， 尤其适用于医疗、金融和政府等高度监管的行业。
- [FoundationDB](https://www.foundationdb.org/) 。FoundationDB 是一个多模型数据库，2015 年被苹果公司收购，并于 2018 年 4 月开源。它的核心是一个分布式键值存储，提供严格的可序列化事务。同时包括智能数据分布以避免写入热点、新的存储引擎、性能优化以及 多区域复制支持。
- [Golem](https://github.com/golemcloud/golem)。持久计算（Durable computing）是分布式计算中的一个新兴运动，它使用显式状态机的架构风格来持久化无服务器计算的内存，以提高容错性和恢复能力。
- Iggy。[Iggy](https://github.com/iggy-rs/iggy) 是一个用 Rust 编写的持久化消息流平台，虽然是一个相对较新的项目，但其功能非常出色。它已经支持 多个流、主题和分区、至多一次投递、消息过期，另外它还通过 QUIC、TCP 和 HTTP 协议支持 TLS。 Iggy 以 单服务器的方式运行， 目前在读写操作中都能实现高吞吐量。随着即将引入的集群和 io_uring 支持，Iggy 很有可能成为 Kafka 的一个替代方案。
- [Iroh](https://www.iroh.computer/) 是一个相对较新的分布式文件存储和内容交付系统，旨在作为现有去中心化系统，如 IPFS（InterPlanetary  File System）的演进。Iroh 和 IPFS 都可以用来创建去中心化网络，以存储、共享和访问使用不透明内容标识 符寻址的内容。然而，Iroh 去掉了 IPFS 的一些 实现限制，例如没有最大区块大小，并通过对文档进行 基于范 围的集合重整 提供数据同步机制。该项目的路线图包括通过 WASM 将技术带入浏览器，这为在 Web 应用程序 中构建去中心化带来了令人兴奋的可能性。
- 大型视觉模型（LVM）平台。大语言模型（LLMs）在当前吸引了如此多的关注，以至于我们往往忽略了大型视觉模型（LVMs）的持续发展。这些模型可用于分割、合成、重建和分析视频流和图像，有时还结合了扩散模型或标准卷积神经网络。视频数据在收集训练数据、分割和标注对象、微调模型以及部署和监控这些模型时，带来了独特的工程挑战。与 LLMs  更适合简单的聊天界面或纯文本 API 不同，计算机视觉工程师或数据科学家必须管理、版本化、注释和分析大 量的视频流数据，这项工作需要一个可视化界面。大型视觉模型（LVM）平台是新兴的一类工具和服务，其中包 括 [V7](https://www.v7labs.com/)、 [Nvidia Deepstream SDK](https://developer.nvidia.com/deepstream-sdk) 和 [Roboflow](https://roboflow.com/)，这些平台正在解决这些挑战。
- OpenBCI Galea 。对脑机接口（BCI）及其在辅助技术中的潜在应用的兴趣正在 不断增长。使用脑电图（EEG）和其他电生理信号的 非侵入性技术为恢复中的患者提供了一种比脑植入物更低风险的替代方案。现在，研究人员和企业家可以在新兴 的平台上构建创新应用，而不必担心低级信号处理和集成挑战。这样的平台的例子包括 Emotive 和 OpenBCI， 它们提供开源硬件和软件用于构建 BCI 应用程序。
- [PGLite](https://github.com/electric-sql/pglite)。是一个构建于WASM 的 PostgreSQL 数据库。与之前需要 Linux 虚拟机的尝试不同，PGLite 直接将  PostgreSQL 构建为 WASM，允许你完全在 web 浏览器中运行它。
- [SpinKube](https://www.spinkube.dev/) 是一个在 Kubernetes 上运行的开源无服务器（serverless）WebAssembly 运行时。虽然  Kubernetes 提供了强大的自动扩展能力，但容器的冷启动时间仍然可能需要预先配置以应对高峰负载。WebAssembly 的毫秒级启动时间为按需工作负载提供了更加动态和灵活的无服务器（serverless）解决方案。
- [Unblocked](https://getunblocked.com/)。提供软件开发生命周期（SDLC）资产和工件的发现功能。它与常见的应用程序生命周期管理  （ALM）和协作工具集成，帮助团队理解代码库及相关资源。通过提供代码的即时相关上下文，Unblocked 改善了代码理解，使导航和理解复杂系统变得更加容易。

### 暂缓



## 工具

### 采纳

- [Bruno](https://github.com/usebruno/bruno) 是一个用于 API 测试、开发和调试的开源桌面工具，类似于 Postman 和 Insomnia 。它旨在通过简单的离线设计提供更卓越的协作、隐私和安全性。集合直接存储在您的文件系统中，采用自定义的纯文本标记语言 Bru  Lang 编写，可以通过 Git 或您选择的版本控制工具进行共享以便协作。Bruno 既可作为桌面应用程序使用，也 可作为 CLI tool。它还提供了官方的 VS Code 扩展，并计划支持其他 IDE。
- [K9s](https://k9scli.io/) 通过集成更详细的图表和视图，显著地提升了其可视化能力。它现在提供了更友好的日志和指标展示功能， 并更加灵活地支持自定义资源（CRDs）的显示。对于 Pods 的操作也得到了扩展，包括与调试工具（如 kubectl  debug）更深入的集成，以及对多集群环境的增强支持。对于 CRD 的支持有显著地提升，现在提供了更好的资源导航和管理能力，并且可以更加流畅地与自定义资源进行交互。快捷键面板也得到了增强。
- [SOPS](https://getsops.io/) 是一个加密文件编辑器，支持多种文件格式的加密，并与密钥管理服务（KMS）兼容。
- 视觉回归测试工具。它们的算法已经从原始的像素级比较进化到更复杂的模式匹配和光学字符识别（OCR）。早期的视觉回归工具产生了很多误报，只有在界面稳定的后期开发阶段才有用。[BackstopJS](https://www.thoughtworks.com/cn/radar/tools/backstopjs)  通过配置选择器和视口来定位页面上的特定元素进行视觉测试，避免了这个问题。但机器学习使得检测和比较视觉元素更加准确，即使在这些元素移动或包含动态内容的情况下。这些工具变得越来越有用，并且具备利用  AI 和机器学习最新进展的优势。现在，几个商业工具，如 Applitools 和Percy ，声称在其视觉回归测试中使用了 AI。

- [Wiz](https://www.wiz.io/) 是一个云安全平台。它能够更早地检测到风险和威胁， 因为它能够持续扫描变更。Wiz 可以检测并警报尚未部署到生产环境的工件（如容器镜像、基础设施代码）以及 生产环境中的工作负载（如容器、虚拟机和云服务）的错误配置、漏洞和泄露的机密。

### 试验

- [AWS Control Tower](https://aws.amazon.com/controltower)。AWS Control Tower 是一个可以在多团队环境中管理 AWS 账户的首选工具。它提供了一个便捷的机制，可以预 配置安全和合规控制，这些控制将自动应用于新的着陆区。
- CCMenu。对于实践持续集成（CI）的团队来说，了解中央构建在 CI 中的状态非常重要。随着远程工作成为常态，团队需要一种适用于开发者个体工 作站的解决方案。在 Mac 上，[CCMenu](https://ccmenu.org/) 就是一款这样的工具，这是一个由 Thoughtworks 员工编写的小应用 程序。
- [ClickHouse](https://clickhouse.com/) 是一个开源的列式在线分析处理（OLAP）数据库，用于实时分析。它于 2009 年作为一个实验项 目启动，之后发展成为一个高性能且线性可扩展的分析数据库。其高效的查询处理引擎结合数据压缩，使其适 合在不进行预聚合的情况下运行交互式查询。
- [Devbox](https://www.jetpack.io/devbox/) 是一个命令行工具，提供了简洁的界面，用于创建可复现 的、按项目定义的本地开发环境，它利用了 Nix 包管理器，但不使用虚拟机或容器。Devbox 极大地简化了团 队的入职流程，因为一旦为代码库配置好环境，在新设备上只需一个 CLI 命令（devbox shell）就能复现已定义 的环境。Devbox 支持 shell 钩子、自定义脚本以及生成 devcontainer.json，以便与 VSCode 集成。
- [Difftastic](https://difftastic.wilfred.me.uk/) 是一种用于在语法感知的基础上高亮显示代码文件差异的工具，和传统的文本 diff 工具（例如经典的  Unixdiff 命令）有很大不同。例如，在像 Java 或 TypeScript 这样的以分号分隔的语言中，Difftastic 会忽略 为了分割长语句而插入的换行符。该工具仅突出显示对程序语法有影响的更改。它首先将文件解析为抽象语法 树，然后使用 Dijkstra 算法计算它们之间的距离。
- [LinearB](https://www.linearb.io/) 是一个软件工程智能平台，为工程领导者提供数据驱动的洞察，以支持持续改进。它对关键领域进行对齐，如基准测试、工作流自动化以及增强开发者体验和生产力的针对性投资。LinearB 集成了源代码、应用生命周期、CI/CD 和沟通工具，使用预配置和自定义的工程指标，提供有关开发者体验、生产力和团队绩效的全面定量洞察。
- [pgvector](https://github.com/pgvector/pgvector) 是一个开源的 PostgreSQL 扩展，用于**进行向量相似性搜索**，允许将向量与结构化数据一起存储在 单一且成熟的数据库中。虽然它缺少一些专用向量数据库的高级功能，但它受益于 PostgreSQL 的 ACID 合规 性、时间点恢复等强大功能。随着生成式 AI 驱动的应用程序的兴起，我们看到越来越多的模式是存储并有效搜 索嵌入向量以进行相似性匹配，pgvector 有效地解决了这一需求。
- [Snapcraft](https://snapcraft.io/docs/snapcraft) 是一个开源的命令行工具，用于在 Ubuntu、其他 Linux 发行版和 macOS 上构建和打包名为 snaps  的自包含应用程序。Snaps 可以在包括 Linux 机器、虚拟环境和车辆车载计算机系统在内的硬件平台上轻松部 署和维护。
- [Spinnaker](http://www.spinnaker.io/) 是由 Netflix 创建的一个开源持续交付平台。它将集群管理和云端烘焙镜像的部署作为核心功能。在之前的版本中，我们提到了缺乏将流水线配置为代码的能力， 但这一问题已通过添加 spin CLI 得到解决。
- [TypeScript OpenAPI](https://github.com/lukeautry/tsoa) （或称 tsoa）是 Swagger 生成 OpenAPI 规范的一个替代方案，用于从代码中直接生成  API 规范。它采用代码优先的方式，**将 TypeScript 控制器和模型作为唯一的真实数据来源**，并使用 TypeScript  注解或装饰器，而不像使用 OpenAPI 工具时需要复杂的文件和配置。它能够生成 2.0 和 3.0 的 API 规范，并且支持为 Express、Hapi 和 Koa 生成路由。如果你在使用 TypeScript 编写 API，值得看看这个项目。
- [Unleash](https://www.getunleash.io/) 既可以用于简 单特性开关，也支持分组和渐进式发布，使其成为适合大规模功能管理的选择。



### 评估

- [Astronomer Cosmos](https://astronomer.github.io/astronomer-cosmos/index.html) 是一个为 Airflow 设计的插件，旨在为 dbt core 工作流提供更原生的支持。
- [ColPali](https://github.com/illuin-tech/colpali) 是一款新兴工具，利用 视觉语言模型 实现 PDF 文档检索，旨在解决从包含图像、图表和表格的多媒体 文档中提取数据的难题，这对于构建强大的 检索增强生成（RAG）应用至关重要。与依赖文本嵌入或光学字符 识别（OCR）技术的传统方法不同，ColPali 处理整页 PDF 文档，使用视觉 Transformer 创建嵌入，综合考虑 文本和视觉内容。这种整体方法不仅提高了文档检索的效果，还增强了对为何检索到特定文档的推理能力，大 大提升了 RAG 在数据丰富的 PDF 文档中的表现。
- [Cursor](https://www.cursor.com/) AI 辅助编程工具的竞赛仍在继续，而其中最引人注目的一个就是 Cursor。Cursor 是一个以 AI 为核心的代码编辑器，旨在通过深度整合 AI 到编码工作流中来提升开发者的生产力。Cursor 展现了基于现有代码库的强大上下文推理能力。尽管其他 AI 代码工具如 GitHub Copilot 已经可以围绕代码片段进行代码生成或 协作，**Cursor 的多行和多文件编辑操作让它脱颖而出**。Cursor 是基于 VSCode 代码库分叉开发的，提供了一 种符合开发者直觉的快速且直观的交互方式。通过快捷键 ctrl/cmd+K 和 ctrl/cmd+L 即可完成强大的操作。 Cursor 在开发者交互和代码库理解方面更为突出。
- [Data Mesh Manager](https://www.datamesh-manager.com/) 提供了典型 data mesh 平台的元数据层。它特别关注数据产品的定义以及使用  OpenContract 倡议规范数据契约，并可以通过相关的 DataContract CLI 集成到构建管道中。该应用还提供 了数据目录，用于发现和探索数据产品及其元数据，并允许进行联邦治理，包括定义数据质量指标和管理数据 质量规则。
- [GitButler](https://gitbutler.com/) 尽管Git的 功能强大且实用，但其命令行界面在管理多个分支和提交暂存方面以复杂性著称。GitButler 是一 个 Git 客户端，它提供了图形界面，旨在简化这一过程。**GitButler 通过独立于 Git 跟踪未提交的文件更改， 并将这些更改暂存到虚拟分支中来实现这一目标**。
- [JetBrains AI Assistant](https://www.jetbrains.com/ai/) 是一款为所有JetBrains IDE 提供支持的编码助手，旨在顺畅集成以支持代码补全、测 试生成和风格指南遵循。它基于 [OpenAI](https://openai.com/) 和 [Google Gemini](https://gemini.google.com/) 等模型，因其能够记住编码风格并在后续会话中保 持一致性输出而脱颖而出。我们的开发人员发现其测试生成功能特别有用，并指出它在处理较长输出时没有稳 定性问题。
- [Mise](https://mise.jdx.dev/) 在多语言环境中工作的开发人员经常发现自己需要管理多个不同语言和工具的版本。mise旨在解决这个问题， 提供一个工具来替代 nvm、 pyenv、rbenv、rustup 等工具，并且可以作为 asdf的直接替代品。Mise  是用 Rust 编写的，以提高 shell 交互的速度；**与使用基于 shell 的 shim 的 asdf 不同，mise 预先修改 PATH  环境变量，从而直接调用工具运行时。**这也是 mise 比 asdf 更快的部分原因。对于那些已经熟悉 asdf 的开发 人员，mise 提供了相同的功能，但有一些关键区别。由于是用 Rust 编写的，mise 更快，并且拥有一些 asdf  所没有的功能，例如能够同时安装同一工具的多个版本，以及更宽容的命令，包括模糊匹配。它还提供了一个 集成的任务运行器，方便执行代码检查、测试、构建、服务器和其他与项目相关的任务。
- [Mockoon](https://mockoon.com/) 是一个开源的 API 模拟工具。它具有直观的界面、可自定义的路由和动态响应功能，还可以自动创建模拟数据集。Mockoon 兼容 OpenAPI，允许生成不同的场景，能够在本地进行测试并与开发流水线集成。你还可以创建“部分模拟”，通过拦截请求，仅模拟 Mockoon 中定义的调用。这部分模拟有助于模拟特定的 API  路由或端点，并将其他请求转发到实际的服务器。Mockoon 是快速搭建模拟 API、改进和自动化开发流程的宝贵工具。
- [Raycast](https://www.raycast.com/) 是一款适用于 macOS 的启动器，允许你通过键盘快速启动应用程序、运行命令、搜索文件并自动化 任务。
- [ReadySet](https://github.com/readysettech/readyset) 是一个适用于 MySQL 和 PostgreSQL 的缓存层。与依赖手动失效的传统缓存解决方案不同， ReadySet 利用数据库复制流来增量更新其缓存。通过 [部分视图物化](https://jon.thesquareplanet.com/papers/osdi18-noria.pdf)，ReadySet 实现了比传统只读副本更低 的尾延迟。ReadySet 与 MySQL 和 PostgreSQL 在协议上兼容，因此可以将其部署在数据库前，以横向扩展 读取工作负载，而无需更改应用程序。
- [Rspack](https://rspack.dev/) 。在开发基于 Web 的前端时，可以从旧的打包工具（比如 Webpack）转向 Vite。该领域的新进者是 Rspack，经过 1.5 年的开发，刚刚发布了 1.0 release。**Rspack 被设计为 Webpack 的直接替代品，兼容  Webpack 生态系统中的插件和加载器。**这在迁移复杂的 Webpack 设置时，相较于 Vite 可能具有一定优势。没有什么比在获取上次代码更改反馈前需要等待一两分钟更能打断开发流程的了。Rspack 使用 Rust 编写，提供的性能显著快于 Webpack， 在许多情况下甚至比 Vite 更快。
- 语义路由。在构建基于 LLM 的应用时，将请求路由到特定代理或触发某一流程之前，确定用户意图是至关重要的。 [Semantic Router](https://github.com/aurelio-labs/semantic-router) 充当 LLM 和代理之间的快速决策层，基于语义意义进行高效且可靠的请求路由。通过使用 向量嵌入推断意图，Semantic Router 减少了不必要的 LLM 调用，提供了一种更加简洁、具有低成本的用户意 图理解方式。它的潜力不仅限于意图推断，还可以作为各种语义任务的多功能构建模块。它的响应速度和灵活 性使其在需要避免 LLM 带来的额外开销，快速实时决策的环境中成为强有力的竞争者。
- 软件工程代理（software engineering agents）。目前在生成式 AI（GenAI）领域最热门的话题之一是软件工程代理（software engineering agents）的概念。 这些编程辅助工具不仅仅是在代码片段上帮助工程师，它们的目标是扩大解决问题的范围，理想情况下能够自主完成任务，且减少人为干预。**其理念是，这些工具能够接收 GitHub issue 或 Jira ticket，提出计划并进行代 码更改，甚至创建供人类审查的 pull request。**这是提升 AI 编程辅助工具影响力的下一步逻辑，但想要实现覆盖广泛编码任务的通用代理的目标仍然非常雄心勃勃，目前的工具尚未令人信服地展示出这一点。正在发布和推广测试版代理的工具包括 [GitHub Copilot Workspace](https://githubnext.com/projects/copilot-workspace)、[qodo flow](https://www.qodo.ai/products/qodo-flow/)、[Tabnine’s](https://www.thoughtworks.com/cn/radar/tools/tabnine) 的 [JIRA 代理](https://www.tabnine.com/blog/introducing-tabnines-ai-agents-for-atlassian-jira/) ，以 及 [Amazon Q Developer](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/software-dev.html)。SWE Bench 基准测试列出了更多此类工具，但建议对 AI 领域的基准测试保持一定的谨慎态度。
- [uv](https://github.com/astral-sh/uv) 。Rust 因为其启动性能非常适合编写命令行工具。之前提到Ruff，这是一个用 Rust 编写的 Python linter。这里我们评估了uv，这是一个用 Rust 编写 的 Python 包管理工具。uv 的价值主张是“超快”，在基准测试中，它的性能大幅超过其他 Python 包管理工具。然而，问题是在构建工具中优化几秒钟是否真的算是一个显著的提升。对于一个包管理系统来说，更重要的是**生态系统、成熟的社区和长期的支持**。
- [Warp](https://www.warp.dev/) 是一款适用于 macOS 和 Linux 的终端工具，它将命令输出分割为块以提高可读性。Warp 提供了AI 驱 动的能力，如智能命令建议和自然语言处理。它还包括笔记本功能，允许用户组织命令和输出，并添加注释和 文档。
- 在 [Atom](https://en.wikipedia.org/wiki/Atom_(text_editor)#History) 文本编辑器项目关闭后，其创建者构建了一个名为 Zed 的新编辑器。Zed 使用 Rust 编写，并经过优 化以充分利用现代硬件，给人感觉非常快速。它具备我们对现代编辑器的所有期望功能：支持多种编程语言、 内置终端以及多缓冲编辑等。通过与多个 LLM 提供商的集成，Zed 还提供 AI 辅助编码功能。



### 暂缓

- [CocoaPods](https://cocoapods.org/) 一直是 Swift 和 Objective-C Cocoa 项目中广受欢迎的依赖管理工具。然而，CocoaPods 团队 宣布，该项目在作为 iOS 和 macOS 开发者关键工具超过十年后，进入了维护模式。尽管工具和其资源仍将继 续可用，但将不再进行主动开发。其鼓励开发者们转向 [Swift Package Manager](https://www.thoughtworks.com/cn/radar/languages-and-frameworks/swift-package-manager)，它与 Xcode 原生集成，并 且获得了来自苹果的更好的长期支持。



## 语言和框架

### 采纳

-  [dbt](https://www.getdbt.com/)是在 ELT 数据管道中实施数据转换的强大且合理的选择。它引入工程上的严谨性，并支持模块化、可测试性和 SQL 转换的可重用性等实践。dbt 集成了 很多云数据仓库、数据湖仓和数 据库，包括 Snowflake、BigQuery、Redshift、Databricks 和 Postgres，并且拥有健康的社区包生态系统。
- [Testcontainers](https://www.testcontainers.org/) 。Testcontainers 是创建可靠测试环境的一个选择。它是一个移植到多种语言的库，可以将常见的测试依赖项进行 Docker化――包括各种类型的数据库、队列技术、云服务以及像网页浏览器这 样的 UI 测试依赖项，并能够在需要时运行自定义 Dockerfile。最近发布了一个 桌面版本，允许对测试会话进 行可视化管理，并能够处理更复杂的场景。

### 试验

- CAP 是一个实现了[Outbox 模式](https://learn.microsoft.com/en-us/dotnet/architecture/microservices/multi-container-microservice-net-applications/subscribe-events#designing-atomicity-and-resiliency-when-publishing-to-the-event-bus) 的 .NET 库。在使用 RabbitMQ 或 Kafka 等分布式消息系统时，经常面临确保数据库更新和事件发布按原子性执行的挑战。CAP 通过在引发事件的同一个数据库事务中记录事件发布的意 图，解决了这一问题。CAP 非常实用，它支持多种数据库和消息平台，并确保至少一次的消息投递。
- [CARLA](https://github.com/carla-simulator/carla) 是一个开源的自动驾驶模拟器，它可用于在生产部署之前测试自动驾驶系统。它在创建和重用车辆、 地形、人类、动物等 3D 模型上具有很强的灵活性，这使得它可以用来模拟各种场景，比如模拟行人走上马路 或遇到迎面而来的特定速度的车辆。那些待测试的自动驾驶系统必须能够识别这些动态参与者并采取适当的行 动，例如刹车。
- [Databricks Asset Bundles](https://docs.databricks.com/en/dev-tools/bundles/index.html)（DABs）， 于 2024 年 4 月 实现基本可用，正逐渐成为打包和部署 Databricks 资 产的首选工具。DABs 支持将工作流和任务的配置以及要在这些任务 中执行的代码打包成一个 bundle，并通过 CI/CD 管道部署到多个环境中。它提供了常见资产类型的模板，并 支持自定义模板，这使得能够为数据工程和机器学习项目创建 定制服务模版。
- [Instructor](https://github.com/jxnl/instructor) 是一个可以请求 从 LLMs 获取结构化输出 的库。您可以定义预期的输出结构，并 在 LLM 未返回您要求的结构时配置重试。由于与 LLM 进行交互时，最佳的终端用户体验往往是将结果流式传 输给他们，而不是等待完整响应，Instructor 还可以处理从流中解析部分结构的任务。
- [Kedro](https://github.com/kedro-org/kedro) 作为 MLOps 工具有了显著的改善，并始终保持对模块化和工程实践的关注，这一点是我们从一开始就 非常喜欢的。突出其模块化的一步是推出了独立的 kedro-datasets 包，该包将代码与数据解耦。Kedro 在其 命令行接口、起始项目模板和遥测功能方面进行了增强。
- [LiteLLM](https://github.com/BerriAI/litellm) 是一个用于无缝集成各种大语言模型（LLM）提供商 API 的库，通过OpenAI API 格式 交互。它支持多 种 提供方和模型，并为文本生成、嵌入和图像生成提供统一的接口。LiteLLM 简化了集成过程，通过匹配每个 提供商的特定端点要求来翻译输入。它还提供了实现生产应用中所需的操作功能的框架，如缓存、日志记录、 速率限制和负载均衡，从而确保不同 LLM 的一致操作。使用 LiteLLM 来轻松切换各种模型，这在模型快速演变的今天尤为必要。
- [LLamaIndex](https://github.com/run-llama/llama_index) 包含能够设计特定领域、上下文增强的 LLM 应用程序的引擎，并支持数据摄取、向量索引和文档 上的自然语言问答等任务。可以使用 LlamaIndex 构建检索增强生成（RAG）流水线，自动化文 档摄取，索引文档嵌入，并根据用户输入查询这些嵌入。使用 LlamaHub，您可以扩展或自定义 LlamaIndex  模块以满足您的需求，例如构建使用您首选的 LLM、嵌入和向量存储提供者的 LLM 应用程序。
- LLM Guardrails 是一套用于防止大语言模型（LLMs）生成有害、使人误解或不相关内容的指南、政策或过滤 器。Guardrails 也可用于保护 LLM 应用免受恶意用户通过操纵输入等技术对其滥用。它们通过为模型设定边界 来作为安全网，确保内容的处理和生成在可控范围内。在这一领域中，诸如 NeMo Guardrails 、Guardrails AI  和 Aporia Guardrails 等框架已经逐渐崭露头角。
- [Medusa](https://medusajs.com/)。大多数用于构建购物网站的电子商务解决方案通常会陷入 80/20 陷阱，即可以轻松构建出 80% 的需求，但对于剩下的 20% 却无能为力。Medusa 提供了一个良好的平衡。它是一个高度可定制的 开源商业平台，允许开发人员创建独特且量身定制的购物体验，可以自我托管或运行在 Medusa 的平台上。 Medusa 基于 Next.js 和 PostgreSQL 构建，通过提供从基本购物车和订单管理到高级功能（如礼品卡模块和 不同地区的税收计算）的全面模块，加快了开发过程。
- [Pkl](https://pkl-lang.org/) 是一种开源的配置语言及工具，最初由苹果公司内部使用而创建。它的主要特点是其类型和验证系统，能 够在部署之前捕捉配置错误。Pkl 可以减少代码重复（例如环境覆盖的情况），并且能够在配置更 改应用到生产环境之前进行验证。它可以生成 JSON、PLIST、YAML 和 .properties 文件，并且具有包括代码 生成在内的广泛集成开发环境（IDE）和语言支持。
- [ROS 2](https://github.com/ros2) 是一个为开发机器人系统设计的开源框架。它提供了一套用于模块化实现应用程序的库和工具，涵盖了 诸如进程间通信、多线程执行和服务质量等功能。ROS 2 在其 前任 的基础上进行了改进，提供了更好的实时 性能、更高的模块化、对多种平台的支持以及合理的默认设置。ROS 2 在汽车行业正在获得越来越多的关注； 它基于节点的架构和基于主题的通信模型，特别适合那些具有复杂且不断发展的车载应用（如自动驾驶功能）的 制造商。
- [seL4](https://sel4.systems/) 是一个高保障、高性能的操 作系统微内核。它使用 形式化验证 方法来“数学上”确保操作系统的行为符合规范。其微内核架构还将核心职 责最小化，以确保系统的稳定性。我们已经看到像蔚来汽车（NIO）这样的电动汽车公司参与 seL4 生态系统， 未来在这一领域可能会有更多的发展。

- [SetFit](https://github.com/huggingface/setfit)。当前大多数基于 AI 的工具都是生成式的――它们生成文本和图像，使用生成式预训练模型（GPTs）来完成这 些任务。而对于需要处理现有文本的用例――例如文本分类或意图识别――sentence transformers 是首选工具。在这个领域，SetFit 是一个用于微调 sentence transformers 的框架。它使用 对比学习来区分不同的意图类别，通常只需非常少量的样本（甚至少于 25 个）就能实现清晰的分类。sentence  transformers 在生成式 AI 系统中也可以发挥作用。
- [vLLM](https://github.com/vllm-project/vllm) 是一个高吞吐量、内存高效的 LLM 推理引擎，既可以在云环境中运行，也可以在本地部署。它无缝支持 多种 模型架构 和流行的开源模型。容器化的  vLLM 工作节点，托管模型如Llama 3.1（8B and 70B）、Mistral 7B 和 Llama-SQL，可以用于开发者编码辅助、 知识搜索和自然语言数据库交互。vLLM 兼容 OpenAI SDK 标准，促进了一致的模型服务。Azure 的 AI 模型 目录 使用自定义推理容器来提升模型服务性能，vLLM 由于其高吞吐量和高效的内存管理，成为默认的推理引 擎。vLLM 框架正在成为大规模模型部署的默认选择。

### 评估

-  [Apache XTable ™](https://xtable.apache.org/) ，这是一个 Apache 孵化器项目，旨在实现 Hudi、Delta 和 Iceberg 之间的全向互操作性。 与 UniForm 类似，XTable 在不创建底层数据副本的情况下，能够在这些格式之间转换元数据。XTable 对于那 些在多个表格格式之间进行实验的团队可能会很有用。
- [dbldatagen](https://github.com/databrickslabs/dbldatagen) 。为数据工程准备测试数据是一个重大挑战。从生产环境转移数据到测试环境存在风险，因此团队通常依赖于编造 数据或合成数据。大多数情况下，成本 较低的程序生成已经足够用。dbldatagen （Databricks Labs Data Generator）就是这样一个工具；它是一个 用于在 Databricks 环境中生成合成数据的 Python 库，适用于测试、基准测试、演示等多种用途。dbldatagen  可以在短时间内生成规模达数十亿行的合成数据，支持多表、变更数据捕获和合并/连接操作等各种场景。它 能够很好地处理 Spark SQL 的基本类型，生成范围和离散值，并应用指定的分布。在 Databricks 生态系统中 创建合成数据时，dbldatagen 是一个值得评估的选项。
- [DeepEval](https://github.com/confident-ai/deepeval) 是一个基于 Python 的开源评估框架，用于评估大语言模型（LLM）的性能。你可以使用它评估使用 流行框架（如 LlamaIndex 或LangChain构建的检索增强生成（RAG）和其他类型的应用程序，也可以用于基 准测试和对比不同模型，以满足你的需求。DeepEval 提供了一个全面的指标和功能套件，用于评估 LLM 的表现，包括幻觉检测、答案相关性和超参数优化。它支持与 pytest 的集成，结合其断言功能，你可以轻松地将测 试套件集成到持续集成（CI）管道中。
- 如今，大多数基于语言模型的应用程序依赖于为特定任务手工调整的提示词模板。[DSPy](https://github.com/stanfordnlp/dspy) 是一个用于开发此类 应用程序的框架，采用了一种不同的方式，摒弃了直接的提示词工程。相反，它引入了围绕程序流程的更高级 抽象（通过可以彼此叠加的 modules），以及优化的指标和用于训练/测试的数据。
-  Flutter for Web。Flutter 以其对 iOS 和 Android 应用程序的跨平台支持而闻名。现在，它已经扩展到更多的平台。并不是每个网页应用都适合使用 Flutter，但Flutter 特别适合诸如 progressive web apps、single-page apps  和将现有 Flutter 移动应用转换为网页的情况。Flutter 已经支持 WebAssembly（WASM）作为其实验性频道中的编译目标，这意味着它正在积极开发中。编译 到 WASM 目标的 Flutter 网页应用的性能远超其 JavaScript 编译目标。不同平台上的近原生性能也是许多开 发者最初选择 Flutter 的原因之一。
- [kotaemon](https://github.com/Cinnamon/kotaemon) 是一个基于检索增强生成（RAG）的开源工具和框架，用于构建针对知识库文档的问答应用程序。它 可以理解多种文档格式，包括 PDF 和 DOC，并提供基于Gradio 的 Web 用户界面，用户可以通过聊天界面组 织和互动知识库。kotaemon 具有内置的 RAG 流水线，并集成了向量存储，且可以通过 SDK 进行扩展。它的 回答中还引用了来源文档，提供网页内联预览和相关性评分。对于想要构建基于 RAG 的文档问答应用程序的用 户来说，这个可定制的框架是一个非常好的起点。
- [Lenis](https://lenis.darkroom.engineering/) 是一个为现代浏览器设计的轻量且强大的平滑滚动库。 它能够实现流畅的滚动体验，例如 WebGL 滚动 同步和视差效果，这使其非常适合那些需要构建流畅、无缝滚动交互页面的团队。
- [LLMLingua](https://github.com/microsoft/LLMLingua) 通过使用小型语言模型压缩提示，去除非必要的 token，从而提高大语言模型（LLM）的效率，并 在性能损失最小的情况下实现这一目标。 这种 方法 使大语言模型（LLM）能够在有效处理较长提示的同时，保 持推理和上下文学习能力，解决了成本效率、推理延迟和上下文处理等挑战。LLMLingua 与各种大语言模型兼 容，无需额外训练，并支持如 LLamaIndex 等框架，它非常适合优化大语言模型的推理性能。
- [Microsoft Autogen](https://github.com/microsoft/autogen) 是一个开源框架，旨在简化 AI 代理的创建和编排，支持多个代理协作解决复杂任务。它支 持自动化和人机协作的工作流程，并兼容多种大语言模型（LLMs）和代理交互工具。
- [Pingora](https://github.com/cloudflare/pingora) 是一个 Rust 搭建框架，旨在构建快速可靠可编程的网络服务。它最开始由 Cloudflare 开发用以 解决  Nginx 的不足，Pingora 已展现出巨大的潜力，像 River 这样的新型代理正是以 Pingora 为基础构建的。
- [Ragas](https://docs.ragas.io/en/stable/) 是一个框架，旨在评估 检索增强生成（RAG） 流水线的性能，解决了评估这些系统中检索和生成组件的 挑战。它提供了结构化的指标，如可靠性、答案相关性和上下文利用率，这些指标有助于评估基于 RAG 系统的 有效性。我们的开发者发现，它在运行定期评估以微调参数（如 top-k 检索和嵌入模型）时非常有用。一些团 队将 Ragas 集成到每天运行的流水线中，以便在提示模板或模型发生变化时进行评估。
- [Score](https://score.dev/)。许多实施自己内部开发平台的组织倾向于创建自己的 平台编排 系统，以在开发人员与其平台托管团队之间强制 执行组织标准。然而，针对安全、一致和合规地托管容器工作负载的铺路平台的基本功能在不同组织之间是相似的。Score 在这一领域显示出了成为标准的潜力。 它是一种以 YAML 形式编写的声明性语言，描述了容器化工作负载的部署方式，以及其运行所需的特定服务和 参数。Score 最初由 Humanitec 开发，作为其 平台编排者 产品的配置语言，但现在作为一个开源项目由云原 生计算基金会 （CNCF）进行管理。在 CNCF 的支持下，Score 有潜力在 Humanitec 产品之外得到更广泛的 使用。它已经发布了两个参考实现：Kubernetes 和 Docker Compose。
- [shadcn](https://ui.shadcn.com/) **通过提供可重用的、可直接复制粘贴的组件，挑战了传统组件库的概念。**这种方法让团队拥有完整的 控制权和所有权，更加容易进行定制和扩展，而这是更受欢迎的传统库如 MUI 和 Chakra UI不足的地方。 **shadcn 使用 [Radix UI](https://www.radix-ui.com/) 和 Tailwind CSS 构建，能够无缝集成到任何基于 React 的应用程序中，非常适合优先 考虑控制和可扩展性的项目。**它还提供一个 CLI，帮助将组件复制并粘贴到项目中。其优点还包括减少隐藏依赖关系，避免紧耦合的实现。对于寻求更加自主且可适应的前端开发方法的团队来说，shadcn 是一个引人注目的替代方案。
- [Slint](https://slint.dev/) 是一个声明式的 GUI 框架，用于为 Rust、C++ 或 JavaScript 应用程序构建原生用户界面。尽管它是一 个多平台的 UI 框架，拥有实时预览、响应式 UI 设计、VS Code 集成 和原生用户体验等重要特性，但我们特别想强调它在嵌入式系统中的实用性。开发嵌入式应用程序的团队经常会面临有限的 UI 开发选项，并且每个选项 都有其权衡之处。Slint 在开发者体验和性能之间提供了完美的平衡，它使用类似 HTML 的易用标记语言，并 可以直接编译为机器代码。在运行时，它还具有低资源占用的优势，这对于嵌入式系统至关重要。它将 web 和移动开发中经过验证的实践引入到了嵌入式生态系统中。
- [SST](https://sst.dev/) 是一个框架，用于将应用程序部署到云环境中，并同时配置应用程序运行所需的所有服务。SST 不仅是一 个 基础设施即代码 工具，它还是一个提供 TypeScript API 的框架，可以定义应用程序环境，在 Git 推送时触 发应用程序部署服务，还配备了一个 GUI 控制台，用于管理生成的应用程序并调用 SST 管理功能。虽然 SST  最初是基于 AWS Cloud Formation 和 CDK，但其最新版本已经在 Terraform 和 Pulumi 之上实现，因此理论 上它是云平台无关的。SST 原生支持部署几种标准的 Web 应用程序框架，包括 Next.js 和 Remix，也支持 无界面 API 应用程序。虽然它与 平台编排 工具如 Kubevela 有一些相似之 处，但它还为开发者提供了便利功能，如实时模式，将 AWS Lambda 调用代理回开发者本地运行的函数。目前，SST 仍然有些新颖，但这个项目及其工具类别值得持续关注。

### 暂缓